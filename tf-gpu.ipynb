{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f743db87",
   "metadata": {},
   "source": [
    "conda create -n drowning_detection_Enhanced python=3.10\n",
    "conda activate drowning_detection_Enhanced\n",
    "pip install -r drowning_detection.txt\n",
    "pip install opencv-python tensorflow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "242d8d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import time\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PyQt5.QtWidgets import (QApplication, QMainWindow, QLabel, QVBoxLayout, QWidget, \n",
    "                             QPushButton, QFileDialog, QHBoxLayout, QGroupBox, QSlider)\n",
    "from PyQt5.QtGui import QImage, QPixmap, QFont, QPalette, QColor\n",
    "from PyQt5.QtCore import Qt, QThread, pyqtSignal\n",
    "from ultralytics import YOLO\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6e1b50e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VideoThread(QThread):\n",
    "    change_pixmap = pyqtSignal(QImage, list, int, bool)\n",
    "    alert_signal = pyqtSignal(bool)\n",
    "\n",
    "    def __init__(self, source=None):\n",
    "        super().__init__()\n",
    "        self.source = source\n",
    "        self.running = True\n",
    "        self.model = YOLO('yolov9c.pt')\n",
    "        self.drowning_threshold = 0.7\n",
    "        self.proximity_threshold = 50\n",
    "        self.track_history = {}\n",
    "        self.alert_status = False\n",
    "        self.alert_counter = 0\n",
    "        self.alert_cooldown = 30  # Frames to maintain alert after detection\n",
    "\n",
    "    def run(self):\n",
    "        cap = cv2.VideoCapture(self.source if self.source else 0)\n",
    "        if not cap.isOpened():\n",
    "            print(\"Error opening video source\")\n",
    "            return\n",
    "\n",
    "        while self.running:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "\n",
    "            # Detect persons with YOLOv9\n",
    "            results = self.model.track(\n",
    "                frame, \n",
    "                persist=True, \n",
    "                classes=[0],  # Only detect persons\n",
    "                conf=0.5,\n",
    "                tracker=\"botsort.yaml\"\n",
    "            )\n",
    "            \n",
    "            annotated_frame = results[0].plot()\n",
    "            boxes = results[0].boxes.xyxy.cpu().numpy()\n",
    "            track_ids = results[0].boxes.id.int().cpu().numpy() if results[0].boxes.id is not None else []\n",
    "            confidences = results[0].boxes.conf.cpu().numpy()\n",
    "            \n",
    "            person_count = len(boxes)\n",
    "            centroids = []\n",
    "            person_info = []\n",
    "            drowning_flags = []\n",
    "            \n",
    "            # Process each detected person\n",
    "            for i, box in enumerate(boxes):\n",
    "                x1, y1, x2, y2 = map(int, box[:4])\n",
    "                person_img = frame[y1:y2, x1:x2]\n",
    "                \n",
    "                if person_img.size == 0:\n",
    "                    continue\n",
    "                    \n",
    "                # Drowning detection logic (simplified - replace with your model)\n",
    "                is_drowning = False\n",
    "                if person_count == 1 and confidences[i] > 0.7:\n",
    "                    is_drowning = True\n",
    "                \n",
    "                # Track centroids for proximity analysis\n",
    "                centroid = ((x1 + x2) // 2, (y1 + y2) // 2)\n",
    "                centroids.append(centroid)\n",
    "                drowning_flags.append(is_drowning)\n",
    "                \n",
    "                # Store person info for GUI display\n",
    "                person_info.append({\n",
    "                    \"id\": track_ids[i] if i < len(track_ids) else i,\n",
    "                    \"position\": (x1, y1, x2, y2),\n",
    "                    \"drowning\": is_drowning\n",
    "                })\n",
    "            \n",
    "            # Proximity analysis for multi-person scenarios\n",
    "            for i in range(len(centroids)):\n",
    "                for j in range(i+1, len(centroids)):\n",
    "                    dist = np.sqrt((centroids[i][0]-centroids[j][0])**2 + \n",
    "                                  (centroids[i][1]-centroids[j][1])**2)\n",
    "                    if dist < self.proximity_threshold and (drowning_flags[i] or drowning_flags[j]):\n",
    "                        self.alert_status = True\n",
    "                        self.alert_counter = self.alert_cooldown\n",
    "            \n",
    "            # Handle alert status\n",
    "            if any(drowning_flags):\n",
    "                self.alert_status = True\n",
    "                self.alert_counter = self.alert_cooldown\n",
    "            \n",
    "            # Decrement alert counter\n",
    "            if self.alert_counter > 0:\n",
    "                self.alert_counter -= 1\n",
    "            else:\n",
    "                self.alert_status = False\n",
    "            \n",
    "            # Convert to RGB for display\n",
    "            rgb_image = cv2.cvtColor(annotated_frame, cv2.COLOR_BGR2RGB)\n",
    "            h, w, ch = rgb_image.shape\n",
    "            bytes_per_line = ch * w\n",
    "            qt_image = QImage(rgb_image.data, w, h, bytes_per_line, QImage.Format_RGB888)\n",
    "            \n",
    "            # Emit signals to update GUI\n",
    "            self.change_pixmap.emit(qt_image, person_info, person_count, self.alert_status)\n",
    "            self.alert_signal.emit(self.alert_status)\n",
    "            \n",
    "            # Control frame rate\n",
    "            time.sleep(0.03)\n",
    "        \n",
    "        cap.release()\n",
    "\n",
    "    def stop(self):\n",
    "        self.running = False\n",
    "        self.wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "42856c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DrowningDetectionApp(QMainWindow):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.setWindowTitle(\"AI Drowning Detection System\")\n",
    "        self.setGeometry(100, 100, 1200, 800)\n",
    "        \n",
    "        # Central widget and layout\n",
    "        central_widget = QWidget()\n",
    "        self.setCentralWidget(central_widget)\n",
    "        main_layout = QHBoxLayout(central_widget)\n",
    "        \n",
    "        # Video display\n",
    "        self.video_label = QLabel(self)\n",
    "        self.video_label.setAlignment(Qt.AlignCenter)\n",
    "        self.video_label.setMinimumSize(800, 600)\n",
    "        self.video_label.setStyleSheet(\"background-color: black;\")\n",
    "        \n",
    "        # Control panel\n",
    "        control_group = QGroupBox(\"Controls\")\n",
    "        control_layout = QVBoxLayout()\n",
    "        \n",
    "        # Alert panel\n",
    "        self.alert_panel = QLabel(\"NO ALERTS\")\n",
    "        self.alert_panel.setAlignment(Qt.AlignCenter)\n",
    "        self.alert_panel.setFont(QFont(\"Arial\", 24, QFont.Bold))\n",
    "        self.alert_panel.setStyleSheet(\"background-color: green; color: white;\")\n",
    "        self.alert_panel.setMinimumHeight(80)\n",
    "        \n",
    "        # Statistics panel\n",
    "        self.stats_label = QLabel(\"Persons Detected: 0\")\n",
    "        self.stats_label.setFont(QFont(\"Arial\", 14))\n",
    "        self.stats_label.setAlignment(Qt.AlignCenter)\n",
    "        \n",
    "        # Person info panel\n",
    "        self.person_info_label = QLabel(\"No persons detected\")\n",
    "        self.person_info_label.setFont(QFont(\"Arial\", 12))\n",
    "        self.person_info_label.setAlignment(Qt.AlignTop | Qt.AlignLeft)\n",
    "        self.person_info_label.setWordWrap(True)\n",
    "        \n",
    "        # Buttons\n",
    "        self.btn_open = QPushButton(\"Open Video File\")\n",
    "        self.btn_open.clicked.connect(self.open_file)\n",
    "        \n",
    "        self.btn_camera = QPushButton(\"Start Camera\")\n",
    "        self.btn_camera.clicked.connect(self.start_camera)\n",
    "        \n",
    "        self.btn_stop = QPushButton(\"Stop Detection\")\n",
    "        self.btn_stop.clicked.connect(self.stop_detection)\n",
    "        \n",
    "        # Threshold controls\n",
    "        prox_slider_layout = QHBoxLayout()\n",
    "        prox_label = QLabel(\"Proximity Threshold:\")\n",
    "        prox_label.setFont(QFont(\"Arial\", 10))\n",
    "        self.prox_slider = QSlider(Qt.Horizontal)\n",
    "        self.prox_slider.setRange(20, 200)\n",
    "        self.prox_slider.setValue(50)\n",
    "        self.prox_slider.valueChanged.connect(self.update_proximity_threshold)\n",
    "        \n",
    "        # Add widgets to layouts\n",
    "        control_layout.addWidget(self.alert_panel)\n",
    "        control_layout.addWidget(self.stats_label)\n",
    "        control_layout.addWidget(self.person_info_label)\n",
    "        control_layout.addStretch(1)\n",
    "        \n",
    "        prox_slider_layout.addWidget(prox_label)\n",
    "        prox_slider_layout.addWidget(self.prox_slider)\n",
    "        control_layout.addLayout(prox_slider_layout)\n",
    "        \n",
    "        control_layout.addWidget(self.btn_open)\n",
    "        control_layout.addWidget(self.btn_camera)\n",
    "        control_layout.addWidget(self.btn_stop)\n",
    "        control_group.setLayout(control_layout)\n",
    "        \n",
    "        # Main layout\n",
    "        main_layout.addWidget(self.video_label, 70)\n",
    "        main_layout.addWidget(control_group, 30)\n",
    "        \n",
    "        # Video thread\n",
    "        self.video_thread = None\n",
    "        \n",
    "        # Alert styling\n",
    "        self.normal_alert_style = \"background-color: green; color: white;\"\n",
    "        self.warning_alert_style = \"background-color: red; color: white;\"\n",
    "        \n",
    "    def open_file(self):\n",
    "        file_name, _ = QFileDialog.getOpenFileName(\n",
    "            self, \"Open Video File\", \"\", \"Video Files (*.mp4 *.avi *.mov)\"\n",
    "        )\n",
    "        if file_name:\n",
    "            self.stop_detection()\n",
    "            self.start_detection(file_name)\n",
    "    \n",
    "    def start_camera(self):\n",
    "        self.stop_detection()\n",
    "        self.start_detection(0)  # 0 for default camera\n",
    "        \n",
    "    def start_detection(self, source):\n",
    "        self.video_thread = VideoThread(source)\n",
    "        self.video_thread.change_pixmap.connect(self.update_image)\n",
    "        self.video_thread.alert_signal.connect(self.update_alert_status)\n",
    "        self.video_thread.start()\n",
    "        \n",
    "    def stop_detection(self):\n",
    "        if self.video_thread and self.video_thread.isRunning():\n",
    "            self.video_thread.stop()\n",
    "            self.video_thread = None\n",
    "            \n",
    "    def update_image(self, image, person_info, person_count, alert_status):\n",
    "        # Update video display\n",
    "        pixmap = QPixmap.fromImage(image)\n",
    "        self.video_label.setPixmap(pixmap.scaled(\n",
    "            self.video_label.width(), \n",
    "            self.video_label.height(),\n",
    "            Qt.KeepAspectRatio,\n",
    "            Qt.SmoothTransformation\n",
    "        ))\n",
    "        \n",
    "        # Update statistics\n",
    "        self.stats_label.setText(f\"Persons Detected: {person_count}\")\n",
    "        \n",
    "        # Update person info\n",
    "        info_text = \"\"\n",
    "        for idx, person in enumerate(person_info):\n",
    "            status = \"DROWNING!\" if person[\"drowning\"] else \"Normal\"\n",
    "            color = \"red\" if person[\"drowning\"] else \"green\"\n",
    "            info_text += (\n",
    "                f\"<b>Person {person['id']}:</b> \"\n",
    "                f\"<span style='color:{color};'>{status}</span><br>\"\n",
    "                f\"Position: {person['position']}<br><br>\"\n",
    "            )\n",
    "        self.person_info_label.setText(info_text or \"No persons detected\")\n",
    "        \n",
    "        # Update alert status\n",
    "        self.update_alert_status(alert_status)\n",
    "    \n",
    "    def update_alert_status(self, alert_status):\n",
    "        if alert_status:\n",
    "            self.alert_panel.setText(\"DROWNING ALERT!\")\n",
    "            self.alert_panel.setStyleSheet(self.warning_alert_style)\n",
    "        else:\n",
    "            self.alert_panel.setText(\"NO ALERTS\")\n",
    "            self.alert_panel.setStyleSheet(self.normal_alert_style)\n",
    "            \n",
    "    def update_proximity_threshold(self, value):\n",
    "        if self.video_thread:\n",
    "            self.video_thread.proximity_threshold = value\n",
    "            \n",
    "    def closeEvent(self, event):\n",
    "        self.stop_detection()\n",
    "        event.accept()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "54b3c9ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x384 (no detections), 326.9ms\n",
      "Speed: 4.0ms preprocess, 326.9ms inference, 941.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 285.0ms\n",
      "Speed: 1.0ms preprocess, 285.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 306.7ms\n",
      "Speed: 1.5ms preprocess, 306.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 304.3ms\n",
      "Speed: 1.0ms preprocess, 304.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 306.1ms\n",
      "Speed: 2.0ms preprocess, 306.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 298.3ms\n",
      "Speed: 1.0ms preprocess, 298.3ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 310.0ms\n",
      "Speed: 1.0ms preprocess, 310.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 299.9ms\n",
      "Speed: 1.0ms preprocess, 299.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 303.1ms\n",
      "Speed: 2.0ms preprocess, 303.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 303.1ms\n",
      "Speed: 2.0ms preprocess, 303.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 309.3ms\n",
      "Speed: 1.0ms preprocess, 309.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 313.0ms\n",
      "Speed: 1.0ms preprocess, 313.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 297.9ms\n",
      "Speed: 2.0ms preprocess, 297.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 310.8ms\n",
      "Speed: 1.0ms preprocess, 310.8ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 300.1ms\n",
      "Speed: 2.0ms preprocess, 300.1ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 300.5ms\n",
      "Speed: 2.0ms preprocess, 300.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 300.1ms\n",
      "Speed: 2.5ms preprocess, 300.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 302.0ms\n",
      "Speed: 1.0ms preprocess, 302.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 299.6ms\n",
      "Speed: 2.0ms preprocess, 299.6ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 304.6ms\n",
      "Speed: 1.0ms preprocess, 304.6ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 300.8ms\n",
      "Speed: 1.0ms preprocess, 300.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 302.3ms\n",
      "Speed: 2.0ms preprocess, 302.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 303.1ms\n",
      "Speed: 2.0ms preprocess, 303.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 301.8ms\n",
      "Speed: 2.0ms preprocess, 301.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 301.6ms\n",
      "Speed: 1.0ms preprocess, 301.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 313.5ms\n",
      "Speed: 2.0ms preprocess, 313.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 301.8ms\n",
      "Speed: 2.0ms preprocess, 301.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 292.5ms\n",
      "Speed: 2.0ms preprocess, 292.5ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 303.4ms\n",
      "Speed: 1.0ms preprocess, 303.4ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 301.7ms\n",
      "Speed: 2.0ms preprocess, 301.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 302.4ms\n",
      "Speed: 1.0ms preprocess, 302.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 298.2ms\n",
      "Speed: 2.0ms preprocess, 298.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 295.4ms\n",
      "Speed: 1.0ms preprocess, 295.4ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 304.7ms\n",
      "Speed: 1.5ms preprocess, 304.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 298.7ms\n",
      "Speed: 1.0ms preprocess, 298.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 300.3ms\n",
      "Speed: 2.0ms preprocess, 300.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 300.2ms\n",
      "Speed: 1.0ms preprocess, 300.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 303.4ms\n",
      "Speed: 1.5ms preprocess, 303.4ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 298.4ms\n",
      "Speed: 2.0ms preprocess, 298.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 299.6ms\n",
      "Speed: 1.5ms preprocess, 299.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 309.9ms\n",
      "Speed: 1.5ms preprocess, 309.9ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 301.6ms\n",
      "Speed: 2.0ms preprocess, 301.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 309.5ms\n",
      "Speed: 1.0ms preprocess, 309.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 329.4ms\n",
      "Speed: 2.0ms preprocess, 329.4ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 322.3ms\n",
      "Speed: 1.0ms preprocess, 322.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 321.3ms\n",
      "Speed: 2.0ms preprocess, 321.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 325.1ms\n",
      "Speed: 2.0ms preprocess, 325.1ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 311.1ms\n",
      "Speed: 2.0ms preprocess, 311.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 324.6ms\n",
      "Speed: 2.0ms preprocess, 324.6ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 320.0ms\n",
      "Speed: 2.0ms preprocess, 320.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 364.2ms\n",
      "Speed: 2.0ms preprocess, 364.2ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 303.5ms\n",
      "Speed: 1.0ms preprocess, 303.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 310.2ms\n",
      "Speed: 1.0ms preprocess, 310.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 304.9ms\n",
      "Speed: 1.0ms preprocess, 304.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 311.2ms\n",
      "Speed: 1.0ms preprocess, 311.2ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 305.2ms\n",
      "Speed: 2.0ms preprocess, 305.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 302.1ms\n",
      "Speed: 2.0ms preprocess, 302.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 304.0ms\n",
      "Speed: 2.0ms preprocess, 304.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 296.5ms\n",
      "Speed: 1.0ms preprocess, 296.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 298.1ms\n",
      "Speed: 1.0ms preprocess, 298.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 303.4ms\n",
      "Speed: 1.0ms preprocess, 303.4ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 305.3ms\n",
      "Speed: 2.0ms preprocess, 305.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 300.2ms\n",
      "Speed: 1.0ms preprocess, 300.2ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 300.5ms\n",
      "Speed: 2.5ms preprocess, 300.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 303.4ms\n",
      "Speed: 2.0ms preprocess, 303.4ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 300.3ms\n",
      "Speed: 1.0ms preprocess, 300.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 298.7ms\n",
      "Speed: 1.0ms preprocess, 298.7ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 310.1ms\n",
      "Speed: 1.0ms preprocess, 310.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 302.5ms\n",
      "Speed: 1.0ms preprocess, 302.5ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 309.0ms\n",
      "Speed: 2.0ms preprocess, 309.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 303.9ms\n",
      "Speed: 1.0ms preprocess, 303.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 303.0ms\n",
      "Speed: 2.0ms preprocess, 303.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 301.4ms\n",
      "Speed: 2.0ms preprocess, 301.4ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 300.5ms\n",
      "Speed: 2.0ms preprocess, 300.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 303.8ms\n",
      "Speed: 2.0ms preprocess, 303.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 319.2ms\n",
      "Speed: 2.0ms preprocess, 319.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 305.0ms\n",
      "Speed: 2.0ms preprocess, 305.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 296.2ms\n",
      "Speed: 2.0ms preprocess, 296.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 302.7ms\n",
      "Speed: 1.5ms preprocess, 302.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 302.4ms\n",
      "Speed: 1.5ms preprocess, 302.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 281.5ms\n",
      "Speed: 2.5ms preprocess, 281.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 304.0ms\n",
      "Speed: 1.5ms preprocess, 304.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 302.4ms\n",
      "Speed: 1.0ms preprocess, 302.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 312.1ms\n",
      "Speed: 2.0ms preprocess, 312.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 307.9ms\n",
      "Speed: 2.0ms preprocess, 307.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 311.1ms\n",
      "Speed: 2.0ms preprocess, 311.1ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 310.1ms\n",
      "Speed: 2.0ms preprocess, 310.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 305.7ms\n",
      "Speed: 2.0ms preprocess, 305.7ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 308.0ms\n",
      "Speed: 2.0ms preprocess, 308.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 301.0ms\n",
      "Speed: 2.5ms preprocess, 301.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 304.8ms\n",
      "Speed: 1.0ms preprocess, 304.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 301.4ms\n",
      "Speed: 2.0ms preprocess, 301.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 306.2ms\n",
      "Speed: 2.0ms preprocess, 306.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 310.2ms\n",
      "Speed: 2.0ms preprocess, 310.2ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 318.3ms\n",
      "Speed: 2.0ms preprocess, 318.3ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 317.2ms\n",
      "Speed: 2.0ms preprocess, 317.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 303.0ms\n",
      "Speed: 2.0ms preprocess, 303.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 306.9ms\n",
      "Speed: 2.0ms preprocess, 306.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\husse\\.conda\\envs\\drowning_detection_Enhanced\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3587: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    app = QApplication(sys.argv)\n",
    "    window = DrowningDetectionApp()\n",
    "    window.show()\n",
    "    sys.exit(app.exec_())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "drowning_detection_Enhanced",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
