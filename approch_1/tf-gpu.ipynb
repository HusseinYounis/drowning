{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f743db87",
   "metadata": {},
   "source": [
    "conda create -n drowning_detection python=3.10\n",
    "conda activate drowning_detection\n",
    "pip install -r drowning_detection.txt\n",
    "pip install opencv-python tensorflow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "242d8d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import cvlib as cv\n",
    "from cvlib.object_detection import draw_bbox\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import joblib\n",
    "from PIL import Image\n",
    "import time\n",
    "import albumentations\n",
    "from IPython.display import display  # For Jupyter\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e2ccf4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model architecture\n",
    "class CustomCNN(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(CustomCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, 5)\n",
    "        self.conv2 = nn.Conv2d(16, 32, 5)\n",
    "        self.conv3 = nn.Conv2d(32, 64, 3)\n",
    "        self.conv4 = nn.Conv2d(64, 128, 5)\n",
    "        self.fc1 = nn.Linear(128, 256)\n",
    "        self.fc2 = nn.Linear(256, num_classes)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.pool(F.relu(self.conv3(x)))\n",
    "        x = self.pool(F.relu(self.conv4(x)))\n",
    "        bs, _, _, _ = x.shape\n",
    "        x = F.adaptive_avg_pool2d(x, 1).reshape(bs, -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "64540b88",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\husse\\.conda\\envs\\drowning_detection\\lib\\site-packages\\sklearn\\base.py:376: InconsistentVersionWarning: Trying to unpickle estimator LabelBinarizer from version 0.22.2.post1 when using version 1.4.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: Load models and setup preprocessing\n",
    "# Update paths to your actual model files\n",
    "lb = joblib.load('lb.pkl')\n",
    "model = CustomCNN(num_classes=len(lb.classes_))\n",
    "model.load_state_dict(torch.load('model.pth', map_location='cpu'))\n",
    "model.eval()\n",
    "\n",
    "aug = albumentations.Compose([\n",
    "    albumentations.Resize(224, 224),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c20f9953",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Detection function (modified for Jupyter)\n",
    "def detect_drowning(source, max_frames=100):\n",
    "    cap = cv2.VideoCapture(source)\n",
    "    if not cap.isOpened():\n",
    "        print(\"Error opening video source\")\n",
    "        return\n",
    "    \n",
    "    plt.figure(figsize=(12, 8))\n",
    "    frame_count = 0\n",
    "    isDrowning = False\n",
    "    \n",
    "    try:\n",
    "        while frame_count < max_frames:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "                \n",
    "            # Object detection\n",
    "            bbox, labels, conf = cv.detect_common_objects(frame)\n",
    "            \n",
    "            if len(bbox) == 1:  # Single person detection\n",
    "                # Prepare image for model\n",
    "                img_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "                img_rgb = img_rgb.astype(np.uint8)  # Ensure correct type\n",
    "                aug_img = aug(image=img_rgb)['image']\n",
    "                tensor_img = torch.tensor(\n",
    "                    np.transpose(aug_img, (2, 0, 1)).astype(np.float32))\n",
    "                tensor_img = tensor_img.unsqueeze(0)\n",
    "                \n",
    "                # Model prediction\n",
    "                with torch.no_grad():\n",
    "                    outputs = model(tensor_img)\n",
    "                    _, pred = torch.max(outputs, 1)\n",
    "                \n",
    "                status = lb.classes_[pred.item()]\n",
    "                isDrowning = (status == 'drowning')\n",
    "                frame = draw_bbox(frame, bbox, labels, conf, isDrowning)\n",
    "                \n",
    "            elif len(bbox) > 1:  # Multi-person logic\n",
    "                centers = []\n",
    "                for box in bbox:\n",
    "                    cx = (box[0] + box[2]) / 2\n",
    "                    cy = (box[1] + box[3]) / 2\n",
    "                    centers.append((cx, cy))\n",
    "                \n",
    "                min_distance = float('inf')\n",
    "                for i in range(len(centers)):\n",
    "                    for j in range(i+1, len(centers)):\n",
    "                        dist = np.sqrt((centers[i][0]-centers[j][0])**2 + \n",
    "                                      (centers[i][1]-centers[j][1])**2)\n",
    "                        min_distance = min(min_distance, dist)\n",
    "                \n",
    "                isDrowning = (min_distance < 50) if centers else False\n",
    "                frame = draw_bbox(frame, bbox, labels, conf, isDrowning)\n",
    "            \n",
    "            # Display in notebook\n",
    "            frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            plt.imshow(frame_rgb)\n",
    "            plt.title(f\"Frame: {frame_count} | Status: {'DROWNING!' if isDrowning else 'Normal'}\")\n",
    "            plt.axis('off')\n",
    "            display(plt.gcf())\n",
    "            clear_output(wait=True)\n",
    "            \n",
    "            frame_count += 1\n",
    "            time.sleep(0.03)  # Control frame rate\n",
    "            \n",
    "    finally:\n",
    "        cap.release()\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "596f4cec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading yolov4.weights from https://github.com/AlexeyAB/darknet/releases/download/darknet_yolo_v3_optimal/yolov4.weights\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99% |####################################################################### |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading yolov3_classes.txt from https://github.com/arunponnusamy/object-detection-opencv/raw/master/yolov3.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |                                                                        |\r"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.11.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\dnn\\src\\darknet\\darknet_io.cpp:705: error: (-215:Assertion failed) separator_index < line.size() in function 'cv::dnn::darknet::ReadDarknetFromCfgStream'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Cell 5: Run detection (choose source)\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# For webcam: source = 0\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# For video file: source = 'path/to/video.mp4'\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[43mdetect_drowning\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mvideos/test/drowning__006_1.mp4\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_frames\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Runs 100 frames from webcam\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[7], line 19\u001b[0m, in \u001b[0;36mdetect_drowning\u001b[1;34m(source, max_frames)\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# Object detection\u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m bbox, labels, conf \u001b[38;5;241m=\u001b[39m \u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetect_common_objects\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(bbox) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:  \u001b[38;5;66;03m# Single person detection\u001b[39;00m\n\u001b[0;32m     22\u001b[0m     \u001b[38;5;66;03m# Prepare image for model\u001b[39;00m\n\u001b[0;32m     23\u001b[0m     img_rgb \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mcvtColor(frame, cv2\u001b[38;5;241m.\u001b[39mCOLOR_BGR2RGB)\n",
      "File \u001b[1;32mc:\\Users\\husse\\.conda\\envs\\drowning_detection\\lib\\site-packages\\cvlib\\object_detection.py:125\u001b[0m, in \u001b[0;36mdetect_common_objects\u001b[1;34m(image, confidence, nms_thresh, model, enable_gpu)\u001b[0m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m initialize:\n\u001b[0;32m    124\u001b[0m     classes \u001b[38;5;241m=\u001b[39m populate_class_labels()\n\u001b[1;32m--> 125\u001b[0m     net \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadNet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweights_file_abs_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig_file_abs_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    126\u001b[0m     initialize \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    128\u001b[0m \u001b[38;5;66;03m# enables opencv dnn module to use CUDA on Nvidia card instead of cpu\u001b[39;00m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.11.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\dnn\\src\\darknet\\darknet_io.cpp:705: error: (-215:Assertion failed) separator_index < line.size() in function 'cv::dnn::darknet::ReadDarknetFromCfgStream'\n"
     ]
    }
   ],
   "source": [
    "# Cell 5: Run detection (choose source)\n",
    "# For webcam: source = 0\n",
    "# For video file: source = 'path/to/video.mp4'\n",
    "\n",
    "# Download YOLOv3 weights and config if not present\n",
    "import os\n",
    "import urllib.request\n",
    "\n",
    "yolo_dir = \"yolo\"\n",
    "os.makedirs(yolo_dir, exist_ok=True)\n",
    "\n",
    "cfg_path = os.path.join(yolo_dir, \"yolov3.cfg\")\n",
    "weights_path = os.path.join(yolo_dir, \"yolov3.weights\")\n",
    "names_path = os.path.join(yolo_dir, \"coco.names\")\n",
    "\n",
    "if not os.path.exists(cfg_path):\n",
    "\turllib.request.urlretrieve(\n",
    "\t\t\"https://raw.githubusercontent.com/pjreddie/darknet/master/cfg/yolov3.cfg\", cfg_path)\n",
    "if not os.path.exists(weights_path):\n",
    "\turllib.request.urlretrieve(\n",
    "\t\t\"https://pjreddie.com/media/files/yolov3.weights\", weights_path)\n",
    "if not os.path.exists(names_path):\n",
    "\turllib.request.urlretrieve(\n",
    "\t\t\"https://raw.githubusercontent.com/pjreddie/darknet/master/data/coco.names\", names_path)\n",
    "\n",
    "# Patch cv.detect_common_objects to use local YOLO files\n",
    "import cvlib as cv\n",
    "def detect_common_objects_custom(img, confidence=0.5, model='yolov3', enable_gpu=False):\n",
    "\treturn cv.detect_common_objects(\n",
    "\t\timg, confidence=confidence, model=model, enable_gpu=enable_gpu,\n",
    "\t\tconfig=cfg_path, weights=weights_path, classes=names_path\n",
    "\t)\n",
    "cv.detect_common_objects = detect_common_objects_custom\n",
    "\n",
    "detect_drowning(source='videos/test/drowning__006_1.mp4', max_frames=100)  # Runs 100 frames from webcam"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "drowning_detection",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
