{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f743db87",
   "metadata": {},
   "source": [
    "conda create -n drowning_detection_Enhanced python=3.10\n",
    "conda activate drowning_detection_Enhanced\n",
    "pip install -r drowning_detection.txt\n",
    "pip install opencv-python tensorflow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "242d8d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import time\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PyQt5.QtWidgets import (QApplication, QMainWindow, QLabel, QVBoxLayout, QWidget, \n",
    "                             QPushButton, QFileDialog, QHBoxLayout, QGroupBox, QSlider)\n",
    "from PyQt5.QtGui import QImage, QPixmap, QFont, QPalette, QColor\n",
    "from PyQt5.QtCore import Qt, QThread, pyqtSignal\n",
    "from ultralytics import YOLO\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6e1b50e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VideoThread(QThread):\n",
    "    change_pixmap = pyqtSignal(QImage, list, int, bool)\n",
    "    alert_signal = pyqtSignal(bool)\n",
    "\n",
    "    def __init__(self, source=None):\n",
    "        super().__init__()\n",
    "        self.source = source\n",
    "        self.running = True\n",
    "        self.model = YOLO('yolov9c.pt')\n",
    "        self.drowning_threshold = 0.7\n",
    "        self.proximity_threshold = 50\n",
    "        self.track_history = {}\n",
    "        self.alert_status = False\n",
    "        self.alert_counter = 0\n",
    "        self.alert_cooldown = 30  # Frames to maintain alert after detection\n",
    "\n",
    "    def run(self):\n",
    "        cap = cv2.VideoCapture(self.source if self.source else 0)\n",
    "        if not cap.isOpened():\n",
    "            print(\"Error opening video source\")\n",
    "            return\n",
    "\n",
    "        while self.running:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "\n",
    "            # Detect persons with YOLOv9\n",
    "            results = self.model.track(\n",
    "                frame, \n",
    "                persist=True, \n",
    "                classes=[0],  # Only detect persons\n",
    "                conf=0.5,\n",
    "                tracker=\"botsort.yaml\"\n",
    "            )\n",
    "            \n",
    "            annotated_frame = results[0].plot()\n",
    "            boxes = results[0].boxes.xyxy.cpu().numpy()\n",
    "            track_ids = results[0].boxes.id.int().cpu().numpy() if results[0].boxes.id is not None else []\n",
    "            confidences = results[0].boxes.conf.cpu().numpy()\n",
    "            \n",
    "            person_count = len(boxes)\n",
    "            centroids = []\n",
    "            person_info = []\n",
    "            drowning_flags = []\n",
    "            \n",
    "            # Process each detected person\n",
    "            for i, box in enumerate(boxes):\n",
    "                x1, y1, x2, y2 = map(int, box[:4])\n",
    "                person_img = frame[y1:y2, x1:x2]\n",
    "                \n",
    "                if person_img.size == 0:\n",
    "                    continue\n",
    "                    \n",
    "                # Drowning detection logic (simplified - replace with your model)\n",
    "                is_drowning = False\n",
    "                if person_count == 1 and confidences[i] > 0.7:\n",
    "                    is_drowning = True\n",
    "                \n",
    "                # Track centroids for proximity analysis\n",
    "                centroid = ((x1 + x2) // 2, (y1 + y2) // 2)\n",
    "                centroids.append(centroid)\n",
    "                drowning_flags.append(is_drowning)\n",
    "                \n",
    "                # Store person info for GUI display\n",
    "                person_info.append({\n",
    "                    \"id\": track_ids[i] if i < len(track_ids) else i,\n",
    "                    \"position\": (x1, y1, x2, y2),\n",
    "                    \"drowning\": is_drowning\n",
    "                })\n",
    "            \n",
    "            # Proximity analysis for multi-person scenarios\n",
    "            for i in range(len(centroids)):\n",
    "                for j in range(i+1, len(centroids)):\n",
    "                    dist = np.sqrt((centroids[i][0]-centroids[j][0])**2 + \n",
    "                                  (centroids[i][1]-centroids[j][1])**2)\n",
    "                    if dist < self.proximity_threshold and (drowning_flags[i] or drowning_flags[j]):\n",
    "                        self.alert_status = True\n",
    "                        self.alert_counter = self.alert_cooldown\n",
    "            \n",
    "            # Handle alert status\n",
    "            if any(drowning_flags):\n",
    "                self.alert_status = True\n",
    "                self.alert_counter = self.alert_cooldown\n",
    "            \n",
    "            # Decrement alert counter\n",
    "            if self.alert_counter > 0:\n",
    "                self.alert_counter -= 1\n",
    "            else:\n",
    "                self.alert_status = False\n",
    "            \n",
    "            # Convert to RGB for display\n",
    "            rgb_image = cv2.cvtColor(annotated_frame, cv2.COLOR_BGR2RGB)\n",
    "            h, w, ch = rgb_image.shape\n",
    "            bytes_per_line = ch * w\n",
    "            qt_image = QImage(rgb_image.data, w, h, bytes_per_line, QImage.Format_RGB888)\n",
    "            \n",
    "            # Emit signals to update GUI\n",
    "            self.change_pixmap.emit(qt_image, person_info, person_count, self.alert_status)\n",
    "            self.alert_signal.emit(self.alert_status)\n",
    "            \n",
    "            # Control frame rate\n",
    "            time.sleep(0.03)\n",
    "        \n",
    "        cap.release()\n",
    "\n",
    "    def stop(self):\n",
    "        self.running = False\n",
    "        self.wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "42856c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DrowningDetectionApp(QMainWindow):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.setWindowTitle(\"AI Drowning Detection System\")\n",
    "        self.setGeometry(100, 100, 1200, 800)\n",
    "        \n",
    "        # Central widget and layout\n",
    "        central_widget = QWidget()\n",
    "        self.setCentralWidget(central_widget)\n",
    "        main_layout = QHBoxLayout(central_widget)\n",
    "        \n",
    "        # Video display\n",
    "        self.video_label = QLabel(self)\n",
    "        self.video_label.setAlignment(Qt.AlignCenter)\n",
    "        self.video_label.setMinimumSize(800, 600)\n",
    "        self.video_label.setStyleSheet(\"background-color: black;\")\n",
    "        \n",
    "        # Control panel\n",
    "        control_group = QGroupBox(\"Controls\")\n",
    "        control_layout = QVBoxLayout()\n",
    "        \n",
    "        # Alert panel\n",
    "        self.alert_panel = QLabel(\"NO ALERTS\")\n",
    "        self.alert_panel.setAlignment(Qt.AlignCenter)\n",
    "        self.alert_panel.setFont(QFont(\"Arial\", 24, QFont.Bold))\n",
    "        self.alert_panel.setStyleSheet(\"background-color: green; color: white;\")\n",
    "        self.alert_panel.setMinimumHeight(80)\n",
    "        \n",
    "        # Statistics panel\n",
    "        self.stats_label = QLabel(\"Persons Detected: 0\")\n",
    "        self.stats_label.setFont(QFont(\"Arial\", 14))\n",
    "        self.stats_label.setAlignment(Qt.AlignCenter)\n",
    "        \n",
    "        # Person info panel\n",
    "        self.person_info_label = QLabel(\"No persons detected\")\n",
    "        self.person_info_label.setFont(QFont(\"Arial\", 12))\n",
    "        self.person_info_label.setAlignment(Qt.AlignTop | Qt.AlignLeft)\n",
    "        self.person_info_label.setWordWrap(True)\n",
    "        \n",
    "        # Buttons\n",
    "        self.btn_open = QPushButton(\"Open Video File\")\n",
    "        self.btn_open.clicked.connect(self.open_file)\n",
    "        \n",
    "        self.btn_camera = QPushButton(\"Start Camera\")\n",
    "        self.btn_camera.clicked.connect(self.start_camera)\n",
    "        \n",
    "        self.btn_stop = QPushButton(\"Stop Detection\")\n",
    "        self.btn_stop.clicked.connect(self.stop_detection)\n",
    "        \n",
    "        # Threshold controls\n",
    "        prox_slider_layout = QHBoxLayout()\n",
    "        prox_label = QLabel(\"Proximity Threshold:\")\n",
    "        prox_label.setFont(QFont(\"Arial\", 10))\n",
    "        self.prox_slider = QSlider(Qt.Horizontal)\n",
    "        self.prox_slider.setRange(20, 200)\n",
    "        self.prox_slider.setValue(50)\n",
    "        self.prox_slider.valueChanged.connect(self.update_proximity_threshold)\n",
    "        \n",
    "        # Add widgets to layouts\n",
    "        control_layout.addWidget(self.alert_panel)\n",
    "        control_layout.addWidget(self.stats_label)\n",
    "        control_layout.addWidget(self.person_info_label)\n",
    "        control_layout.addStretch(1)\n",
    "        \n",
    "        prox_slider_layout.addWidget(prox_label)\n",
    "        prox_slider_layout.addWidget(self.prox_slider)\n",
    "        control_layout.addLayout(prox_slider_layout)\n",
    "        \n",
    "        control_layout.addWidget(self.btn_open)\n",
    "        control_layout.addWidget(self.btn_camera)\n",
    "        control_layout.addWidget(self.btn_stop)\n",
    "        control_group.setLayout(control_layout)\n",
    "        \n",
    "        # Main layout\n",
    "        main_layout.addWidget(self.video_label, 70)\n",
    "        main_layout.addWidget(control_group, 30)\n",
    "        \n",
    "        # Video thread\n",
    "        self.video_thread = None\n",
    "        \n",
    "        # Alert styling\n",
    "        self.normal_alert_style = \"background-color: green; color: white;\"\n",
    "        self.warning_alert_style = \"background-color: red; color: white;\"\n",
    "        \n",
    "    def open_file(self):\n",
    "        file_name, _ = QFileDialog.getOpenFileName(\n",
    "            self, \"Open Video File\", \"\", \"Video Files (*.mp4 *.avi *.mov)\"\n",
    "        )\n",
    "        if file_name:\n",
    "            self.stop_detection()\n",
    "            self.start_detection(file_name)\n",
    "    \n",
    "    def start_camera(self):\n",
    "        self.stop_detection()\n",
    "        self.start_detection(0)  # 0 for default camera\n",
    "        \n",
    "    def start_detection(self, source):\n",
    "        self.video_thread = VideoThread(source)\n",
    "        self.video_thread.change_pixmap.connect(self.update_image)\n",
    "        self.video_thread.alert_signal.connect(self.update_alert_status)\n",
    "        self.video_thread.start()\n",
    "        \n",
    "    def stop_detection(self):\n",
    "        if self.video_thread and self.video_thread.isRunning():\n",
    "            self.video_thread.stop()\n",
    "            self.video_thread = None\n",
    "            \n",
    "    def update_image(self, image, person_info, person_count, alert_status):\n",
    "        # Update video display\n",
    "        pixmap = QPixmap.fromImage(image)\n",
    "        self.video_label.setPixmap(pixmap.scaled(\n",
    "            self.video_label.width(), \n",
    "            self.video_label.height(),\n",
    "            Qt.KeepAspectRatio,\n",
    "            Qt.SmoothTransformation\n",
    "        ))\n",
    "        \n",
    "        # Update statistics\n",
    "        self.stats_label.setText(f\"Persons Detected: {person_count}\")\n",
    "        \n",
    "        # Update person info\n",
    "        info_text = \"\"\n",
    "        for idx, person in enumerate(person_info):\n",
    "            status = \"DROWNING!\" if person[\"drowning\"] else \"Normal\"\n",
    "            color = \"red\" if person[\"drowning\"] else \"green\"\n",
    "            info_text += (\n",
    "                f\"<b>Person {person['id']}:</b> \"\n",
    "                f\"<span style='color:{color};'>{status}</span><br>\"\n",
    "                f\"Position: {person['position']}<br><br>\"\n",
    "            )\n",
    "        self.person_info_label.setText(info_text or \"No persons detected\")\n",
    "        \n",
    "        # Update alert status\n",
    "        self.update_alert_status(alert_status)\n",
    "    \n",
    "    def update_alert_status(self, alert_status):\n",
    "        if alert_status:\n",
    "            self.alert_panel.setText(\"DROWNING ALERT!\")\n",
    "            self.alert_panel.setStyleSheet(self.warning_alert_style)\n",
    "        else:\n",
    "            self.alert_panel.setText(\"NO ALERTS\")\n",
    "            self.alert_panel.setStyleSheet(self.normal_alert_style)\n",
    "            \n",
    "    def update_proximity_threshold(self, value):\n",
    "        if self.video_thread:\n",
    "            self.video_thread.proximity_threshold = value\n",
    "            \n",
    "    def closeEvent(self, event):\n",
    "        self.stop_detection()\n",
    "        event.accept()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "54b3c9ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 person, 400.4ms\n",
      "Speed: 7.0ms preprocess, 400.4ms inference, 1179.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 325.8ms\n",
      "Speed: 2.0ms preprocess, 325.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 334.9ms\n",
      "Speed: 2.0ms preprocess, 334.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 316.1ms\n",
      "Speed: 2.0ms preprocess, 316.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 307.5ms\n",
      "Speed: 2.0ms preprocess, 307.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 323.9ms\n",
      "Speed: 2.0ms preprocess, 323.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 320.2ms\n",
      "Speed: 1.0ms preprocess, 320.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 330.6ms\n",
      "Speed: 2.0ms preprocess, 330.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 313.7ms\n",
      "Speed: 2.0ms preprocess, 313.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 321.1ms\n",
      "Speed: 2.5ms preprocess, 321.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 320.0ms\n",
      "Speed: 2.0ms preprocess, 320.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 326.9ms\n",
      "Speed: 0.0ms preprocess, 326.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 325.4ms\n",
      "Speed: 2.0ms preprocess, 325.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 325.7ms\n",
      "Speed: 0.0ms preprocess, 325.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 323.6ms\n",
      "Speed: 1.5ms preprocess, 323.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 326.5ms\n",
      "Speed: 1.0ms preprocess, 326.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 321.0ms\n",
      "Speed: 1.5ms preprocess, 321.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 323.4ms\n",
      "Speed: 2.4ms preprocess, 323.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 320.2ms\n",
      "Speed: 2.0ms preprocess, 320.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 326.9ms\n",
      "Speed: 1.0ms preprocess, 326.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 328.2ms\n",
      "Speed: 0.0ms preprocess, 328.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 339.8ms\n",
      "Speed: 0.5ms preprocess, 339.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 327.3ms\n",
      "Speed: 3.4ms preprocess, 327.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 341.5ms\n",
      "Speed: 0.0ms preprocess, 341.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 330.4ms\n",
      "Speed: 2.0ms preprocess, 330.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 320.5ms\n",
      "Speed: 2.0ms preprocess, 320.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 300.2ms\n",
      "Speed: 2.0ms preprocess, 300.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 326.5ms\n",
      "Speed: 2.0ms preprocess, 326.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 318.4ms\n",
      "Speed: 2.0ms preprocess, 318.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 315.2ms\n",
      "Speed: 1.5ms preprocess, 315.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 326.4ms\n",
      "Speed: 2.0ms preprocess, 326.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 320.9ms\n",
      "Speed: 2.0ms preprocess, 320.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 312.7ms\n",
      "Speed: 1.0ms preprocess, 312.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 320.5ms\n",
      "Speed: 2.0ms preprocess, 320.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 318.9ms\n",
      "Speed: 2.0ms preprocess, 318.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 322.4ms\n",
      "Speed: 1.0ms preprocess, 322.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 319.5ms\n",
      "Speed: 2.0ms preprocess, 319.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 325.5ms\n",
      "Speed: 2.0ms preprocess, 325.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 321.7ms\n",
      "Speed: 2.5ms preprocess, 321.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 319.5ms\n",
      "Speed: 2.0ms preprocess, 319.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 320.9ms\n",
      "Speed: 2.0ms preprocess, 320.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 320.2ms\n",
      "Speed: 2.0ms preprocess, 320.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 327.4ms\n",
      "Speed: 3.2ms preprocess, 327.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 322.3ms\n",
      "Speed: 1.5ms preprocess, 322.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 299.3ms\n",
      "Speed: 3.4ms preprocess, 299.3ms inference, 4.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 320.1ms\n",
      "Speed: 0.0ms preprocess, 320.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 312.3ms\n",
      "Speed: 2.5ms preprocess, 312.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 326.5ms\n",
      "Speed: 2.0ms preprocess, 326.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 327.9ms\n",
      "Speed: 2.0ms preprocess, 327.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 325.6ms\n",
      "Speed: 1.0ms preprocess, 325.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 309.3ms\n",
      "Speed: 2.0ms preprocess, 309.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 320.5ms\n",
      "Speed: 1.0ms preprocess, 320.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 309.1ms\n",
      "Speed: 1.5ms preprocess, 309.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 318.1ms\n",
      "Speed: 2.0ms preprocess, 318.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 312.9ms\n",
      "Speed: 2.5ms preprocess, 312.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 316.6ms\n",
      "Speed: 1.0ms preprocess, 316.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 313.5ms\n",
      "Speed: 2.0ms preprocess, 313.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 321.3ms\n",
      "Speed: 2.0ms preprocess, 321.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 312.6ms\n",
      "Speed: 2.0ms preprocess, 312.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 318.4ms\n",
      "Speed: 1.5ms preprocess, 318.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 334.7ms\n",
      "Speed: 2.5ms preprocess, 334.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 349.7ms\n",
      "Speed: 2.5ms preprocess, 349.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 337.3ms\n",
      "Speed: 1.0ms preprocess, 337.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 325.7ms\n",
      "Speed: 2.0ms preprocess, 325.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 326.0ms\n",
      "Speed: 2.0ms preprocess, 326.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 315.1ms\n",
      "Speed: 2.0ms preprocess, 315.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 315.4ms\n",
      "Speed: 2.0ms preprocess, 315.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 316.9ms\n",
      "Speed: 2.0ms preprocess, 316.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 319.2ms\n",
      "Speed: 2.5ms preprocess, 319.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 333.2ms\n",
      "Speed: 2.0ms preprocess, 333.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 336.2ms\n",
      "Speed: 2.0ms preprocess, 336.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 301.6ms\n",
      "Speed: 2.0ms preprocess, 301.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 316.2ms\n",
      "Speed: 2.0ms preprocess, 316.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 312.8ms\n",
      "Speed: 2.0ms preprocess, 312.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 319.5ms\n",
      "Speed: 2.0ms preprocess, 319.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 290.0ms\n",
      "Speed: 2.0ms preprocess, 290.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 321.4ms\n",
      "Speed: 2.0ms preprocess, 321.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 323.8ms\n",
      "Speed: 2.0ms preprocess, 323.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 319.8ms\n",
      "Speed: 2.0ms preprocess, 319.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 322.0ms\n",
      "Speed: 2.0ms preprocess, 322.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 317.5ms\n",
      "Speed: 2.0ms preprocess, 317.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 325.9ms\n",
      "Speed: 1.0ms preprocess, 325.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 314.8ms\n",
      "Speed: 2.0ms preprocess, 314.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 307.4ms\n",
      "Speed: 2.0ms preprocess, 307.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 316.2ms\n",
      "Speed: 2.5ms preprocess, 316.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 323.0ms\n",
      "Speed: 2.0ms preprocess, 323.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 322.4ms\n",
      "Speed: 2.0ms preprocess, 322.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 303.1ms\n",
      "Speed: 2.0ms preprocess, 303.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 321.0ms\n",
      "Speed: 1.5ms preprocess, 321.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 322.7ms\n",
      "Speed: 2.0ms preprocess, 322.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 331.9ms\n",
      "Speed: 1.5ms preprocess, 331.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 319.9ms\n",
      "Speed: 2.0ms preprocess, 319.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 310.9ms\n",
      "Speed: 1.0ms preprocess, 310.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 316.3ms\n",
      "Speed: 2.0ms preprocess, 316.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 336.4ms\n",
      "Speed: 2.0ms preprocess, 336.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 330.7ms\n",
      "Speed: 1.5ms preprocess, 330.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 328.9ms\n",
      "Speed: 2.0ms preprocess, 328.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 350.8ms\n",
      "Speed: 2.0ms preprocess, 350.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 323.5ms\n",
      "Speed: 2.0ms preprocess, 323.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 321.8ms\n",
      "Speed: 2.0ms preprocess, 321.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 347.8ms\n",
      "Speed: 1.5ms preprocess, 347.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 329.1ms\n",
      "Speed: 2.0ms preprocess, 329.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 320.8ms\n",
      "Speed: 1.0ms preprocess, 320.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 315.0ms\n",
      "Speed: 2.0ms preprocess, 315.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 320.2ms\n",
      "Speed: 2.0ms preprocess, 320.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 309.2ms\n",
      "Speed: 2.0ms preprocess, 309.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 320.4ms\n",
      "Speed: 2.0ms preprocess, 320.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 314.9ms\n",
      "Speed: 2.0ms preprocess, 314.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 326.5ms\n",
      "Speed: 1.5ms preprocess, 326.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 331.7ms\n",
      "Speed: 2.0ms preprocess, 331.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 312.6ms\n",
      "Speed: 0.0ms preprocess, 312.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 318.2ms\n",
      "Speed: 2.0ms preprocess, 318.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 316.0ms\n",
      "Speed: 2.0ms preprocess, 316.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 325.3ms\n",
      "Speed: 3.4ms preprocess, 325.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 313.3ms\n",
      "Speed: 0.0ms preprocess, 313.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 343.7ms\n",
      "Speed: 1.5ms preprocess, 343.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 349.5ms\n",
      "Speed: 2.0ms preprocess, 349.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 322.0ms\n",
      "Speed: 2.0ms preprocess, 322.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 318.0ms\n",
      "Speed: 2.5ms preprocess, 318.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 356.6ms\n",
      "Speed: 2.0ms preprocess, 356.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 345.8ms\n",
      "Speed: 2.0ms preprocess, 345.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 354.0ms\n",
      "Speed: 2.0ms preprocess, 354.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 326.6ms\n",
      "Speed: 2.0ms preprocess, 326.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 341.0ms\n",
      "Speed: 2.5ms preprocess, 341.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 332.2ms\n",
      "Speed: 2.5ms preprocess, 332.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 327.5ms\n",
      "Speed: 2.5ms preprocess, 327.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 334.2ms\n",
      "Speed: 0.0ms preprocess, 334.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 327.1ms\n",
      "Speed: 2.0ms preprocess, 327.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    app = QApplication(sys.argv)\n",
    "    window = DrowningDetectionApp()\n",
    "    window.show()\n",
    "    sys.exit(app.exec_())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "drowning_detection_Enhanced",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
